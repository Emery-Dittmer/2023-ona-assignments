{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb2eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyvis==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4edb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1179c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0777dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da805411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c06e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13452\\710426514.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Connections.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#df = pd.read_csv('Connections.csv',skiprows=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#df = pd.read_csv('Julie_Connections.csv',skiprows=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df['Full Name']= df.apply(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataSci\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Connections.csv')\n",
    "#df = pd.read_csv('Connections.csv',skiprows=3)\n",
    "#df = pd.read_csv('Julie_Connections.csv',skiprows=3)\n",
    "\n",
    "df['Full Name']= df.apply(\n",
    "    lambda x: str(x['First Name']) +\" \"+ str(x['Last Name']) ,\n",
    "    axis=1)\n",
    "    #lambda x: str(x['First Name']) +\" \"+ str(x['Last Name'])[0] , axis=1)\n",
    "df=df.dropna(subset=['Company', 'Position'])\n",
    "df=df.groupby(\"Company\").filter(lambda x: len(x) > 1)\n",
    "\n",
    "df['Count_Company'] = df.groupby('Company')['Company'].transform('size')\n",
    "df['Count_Company']=df['Count_Company'].astype(int)\n",
    "\n",
    "df['Position_Count'] = df.groupby('Position')['Position'].transform('size')\n",
    "df['Position_Count']=df['Position_Count'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.treemap(df, path=['Company', 'Position'],\n",
    "           width=1000,\n",
    "           height=1000,\n",
    "           color='Count_Company',\n",
    "           color_continuous_scale='YlGnBu',\n",
    "           color_continuous_midpoint=np.average(df['Count_Company']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.treemap(df, path=['Position','Company'],\n",
    "           width=1000,\n",
    "           height=1000,\n",
    "           color='Position_Count',\n",
    "           color_continuous_scale='Inferno',\n",
    "           color_continuous_midpoint=np.average(df['Position_Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "net = Network(notebook=True)\n",
    "G=nx.from_pandas_edgelist(df, \n",
    "                        source='Company', \n",
    "                        target='Full Name', \n",
    "                        edge_attr=None, \n",
    "                        create_using=None, \n",
    "                        edge_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(131)\n",
    "nx.draw(G,with_labels=True)\n",
    "\n",
    "plt.subplot(132)\n",
    "nx.draw_networkx(G)\n",
    "\n",
    "plt.subplot(133)\n",
    "nx.draw_circular(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff65e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(231)\n",
    "nx.draw_kamada_kawai(G)\n",
    "\n",
    "plt.subplot(232)\n",
    "nx.draw_random(G)\n",
    "\n",
    "plt.subplot(233)\n",
    "nx.draw_spring(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)\n",
    "nx.draw_networkx(G)\n",
    "nx.draw_circular(G)\n",
    "nx.draw_kamada_kawai(G)\n",
    "nx.draw_random(G)\n",
    "nx.draw_spring(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a330c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_kamada_kawai(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a722548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populates the nodes and edges data structures\n",
    "from pyvis.network import Network\n",
    "nt = Network(notebook=True)\n",
    "nt.from_nx(G)\n",
    "nt.toggle_physics(True)\n",
    "nt.show_buttons(filter_=['physics'])\n",
    "nt.show('nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7070331",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\",notebook=True,filter_menu=True)\n",
    "\n",
    "# set the physics layout of the network\n",
    "net.barnes_hut()\n",
    "\n",
    "sources = df['Company']\n",
    "targets = df['Full Name']\n",
    "weights = df['Count_Company']\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "                src = e[0]\n",
    "                dst = e[1]\n",
    "                w = e[2]\n",
    "\n",
    "                net.add_node(src, src, title=src)\n",
    "                net.add_node(dst, dst, title=dst)\n",
    "                net.add_edge(src, dst, value=w)\n",
    "\n",
    "neighbor_map = net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in net.nodes:\n",
    "                node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "                node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "net.show(\"network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c13a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2f6df6",
   "metadata": {},
   "source": [
    "## Julie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Julie_Connections.csv',skiprows=3)\n",
    "df1=df.groupby(\"Company\").filter(lambda x: len(x) > 1)\n",
    "df1['Count'] = df1.groupby('Company')['Company'].transform('size')\n",
    "df1['Count']=df1['Count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e917497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.dropna(subset=['Company', 'Position'])\n",
    "px.treemap(df1, path=['Company', 'Position'],\n",
    "           width=1000,\n",
    "           height=1000,\n",
    "           color='Count',\n",
    "           color_continuous_scale='Sunset',\n",
    "           color_continuous_midpoint=np.average(df1['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.groupby(\"Position\").filter(lambda x: len(x) > 1)\n",
    "df1['Count'] = df1.groupby('Position')['Position'].transform('size')\n",
    "df1['Count']=df1['Count'].astype(int)\n",
    "px.treemap(df1, path=['Position','Company'],\n",
    "           width=1000,\n",
    "           height=1000,\n",
    "           color='Count',\n",
    "           color_continuous_scale='Tropic',\n",
    "           color_continuous_midpoint=np.average(df1['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d5bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
